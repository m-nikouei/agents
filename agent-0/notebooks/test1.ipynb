{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Ollama in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s think step by step about what LangChain is. Here\\'s a breakdown, thinking through the different aspects:\\n\\n**1. The Core Problem LangChain Tries to Solve:**\\n\\n*   **Large Language Models (LLMs) are Powerful, But Limited:** LLMs like GPT-3, GPT-4, Gemini, and others are amazing at generating text, answering questions, and more. However, they primarily operate based on the data they were trained on. They don\\'t easily connect to external data sources, interact with tools, or remember past interactions in a structured way. They\\'re like brilliant but isolated thinkers.\\n*   **Need to Connect LLMs to the \"Real World\":** To be truly useful, LLMs need to be integrated with external systems: databases, APIs, search engines, other tools, and importantly, the ability to *remember* information across multiple interactions (conversation history).\\n\\n**2. What LangChain *Is*:**\\n\\n*   **A Framework, Not a Model:** LangChain isn’t a language model itself. It’s a framework designed to make it easier to *build applications* using LLMs. Think of it like a toolkit for developers working with LLMs.\\n*   **Focus on Composition and Chains:** The key concept is \"chains.\"  A chain is a sequence of calls to LLMs or other utilities. These chains allow you to combine different components to accomplish more complex tasks. LangChain provides components and abstractions to make creating these chains simpler.\\n*   **Key Components (These are like the \"building blocks\"):**\\n    *   **Models:**  Provides interfaces to different LLMs (OpenAI, Cohere, Hugging Face, etc.) - abstracts away the details of each specific model.\\n    *   **Prompts:**  Helps you design effective prompts for LLMs, including prompt templates and example selectors. A good prompt is crucial for getting the LLM to do what you want.\\n    *   **Chains:**  Sequences of calls - these are the heart of LangChain.  There are pre-built chains for common tasks (question answering, summarization, etc.) and the ability to build your own.\\n    *   **Indexes:** Structures that allow LLMs to access and reason about external data. This includes document loaders, text splitters, vectorstores (for semantic search), and retrievers.  This is critical for grounding LLMs in specific knowledge bases.\\n    *   **Memory:**  Allows LLMs to remember previous interactions within a conversation.  This makes for more contextually aware and personalized experiences.\\n    *   **Agents:** Agents use an LLM to decide which actions to take. They can use tools (like search engines, calculators, or other APIs) to answer questions or perform tasks. It\\'s like giving the LLM the ability to \"think\" and act on its decisions.\\n\\n**3. What LangChain *Allows You to Do*:**\\n\\n*   **Build Question Answering Systems:** Connect LLMs to your own documents or data sources.\\n*   **Create Chatbots:** Build more engaging and context-aware chatbots with memory.\\n*   **Automate Tasks:** Combine LLMs with tools to automate complex workflows.\\n*   **Generate Creative Content:**  Build applications that use LLMs to write code, compose music, or create other creative content.\\n*   **Reason and Interact with External Tools:** Agents can use LLMs to plan a series of actions using various tools.\\n\\n**4. Analogy:**\\n\\nThink of it like this:\\n\\n*   **LLM:** The engine of a car - powerful but needs direction.\\n*   **LangChain:** The chassis, steering wheel, navigation system, and other components that allow you to *control* the engine and make it do something useful.\\n\\n\\n\\nIn short, LangChain is a framework for building applications powered by LLMs, focusing on connecting them to data, tools, and memory. It simplifies the process of building complex LLM-powered systems.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:12b\")\n",
    "\n",
    "chain = prompt | model  \n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env0-py312-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
